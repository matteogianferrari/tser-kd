{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbU6l7S97lxP"
      },
      "source": [
        "\n",
        "#**SCNN Student Model - TSER for KD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUaD-Ggk7srE"
      },
      "source": [
        "#**Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olxJj3qN6_V0"
      },
      "source": [
        "---\n",
        "**Install Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z2PLshIm4l-1"
      },
      "outputs": [],
      "source": [
        "!pip install snntorch dagshub mlflow pynvml --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK4Z89UZjjxc"
      },
      "source": [
        "---\n",
        "**GitHub Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbrA52Sajdhf",
        "outputId": "482b5409-5169-447f-ae20-69dab09281d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tser-kd' already exists and is not an empty directory.\n",
            "/content/tser-kd\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "\n",
        "# Sets environ variables for GitHub\n",
        "os.environ['GITHUB_TOKEN'] = userdata.get('GITHUB_TOKEN')\n",
        "os.environ['USER'] = userdata.get('USER')\n",
        "\n",
        "# Clones the repo and changes dir\n",
        "!git clone -b dev https://${GITHUB_TOKEN}@github.com/${USER}/tser-kd.git\n",
        "%cd tser-kd/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t6fX02G7R8a"
      },
      "source": [
        "---\n",
        "**Set Seed for Experiment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zNdOlLK92P3",
        "outputId": "04acd343-50b1-44e9-9fb3-b567a2532ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "from tser_kd.utils import setup_seed\n",
        "\n",
        "\n",
        "setup_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnYeSVRw7UeJ"
      },
      "source": [
        "---\n",
        "**Device Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nHFtZ8Mu7U0W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# Selects the device for the experiment\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CpVNA4i7awv"
      },
      "source": [
        "---\n",
        "**MLFlow Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "KQGoJkQ18pvU",
        "outputId": "a0f639ff-fda2-427a-8406-f5e3afc685e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as matteogianferrari\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as matteogianferrari\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"matteogianferrari/tser-kd\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"matteogianferrari/tser-kd\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository matteogianferrari/tser-kd initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository matteogianferrari/tser-kd initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import mlflow\n",
        "from mlflow import MlflowClient\n",
        "import dagshub\n",
        "\n",
        "\n",
        "# Sets environ variables for MLFlow\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = userdata.get('USER')\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = userdata.get('MLFLOW_TRACKING_PASSWORD')\n",
        "\n",
        "# Init DagsHub\n",
        "dagshub.init(repo_owner='matteogianferrari', repo_name='tser-kd', mlflow=True)\n",
        "TRACKING_URI = \"https://dagshub.com/matteogianferrari/tser-kd.mlflow\"\n",
        "\n",
        "# Sets MLFlow tracking URI\n",
        "mlflow.set_tracking_uri(TRACKING_URI)\n",
        "\n",
        "# Sets MLFLow experiment name\n",
        "experiment_name = \"TSER-KD Student\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbe-kHtd8-qc"
      },
      "source": [
        "#**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gMz9f1SKh3jz"
      },
      "outputs": [],
      "source": [
        "# Hyperparamter dictionary\n",
        "h_dict = {\n",
        "    \"BETA\": 0.5, \"V_th\": 1.0,                               # Leaky Neuron\n",
        "    \"MAX_EPOCHS\": 15, \"BATCH_SIZE\": 32,                    # Training\n",
        "    \"LR_SCHEDULER\": \"CosineAnnealingLR\", \"BASE_LR\": 1e-3,   # LR\n",
        "    \"OPTIMIZER\": \"AdamW\", \"WEIGHT_DECAY\": 5e-4,             # Optimizer\n",
        "    \"ES_PATIENCE\": 100, \"ES_DELTA\": 1e-4,                    # Early Stopping\n",
        "    \"HARDWARE\": \"A100\",                                     # GPU\n",
        "    \"ENCODER\": \"Static\", \"T\": 4,                            # Encoder\n",
        "    \"LEARN_BETA\": False, \"LEARN_THRESHOLD\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II8DpGBh-xKh"
      },
      "source": [
        "#**CIFAR10 Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flJX0Vd9F0Hz"
      },
      "source": [
        "---\n",
        "**Data Loaders Creation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D3pB3mNi-1W2"
      },
      "outputs": [],
      "source": [
        "from tser_kd.dataset import load_mnist_data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, num_classes = load_mnist_data()\n",
        "\n",
        "# Creates the train and test DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=h_dict['BATCH_SIZE'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=h_dict['BATCH_SIZE'], shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFPX6pbwIDSz"
      },
      "source": [
        "#**S-CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBCYeTfkm7rm"
      },
      "source": [
        "---\n",
        "**Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2489bmuzwoh4"
      },
      "outputs": [],
      "source": [
        "from tser_kd.model.student import make_student_model\n",
        "\n",
        "\n",
        "# SNN\n",
        "s_model = make_student_model(\n",
        "    arch='scnn',\n",
        "    in_channels=1,\n",
        "    num_classes=num_classes,\n",
        "    beta=h_dict['BETA'],\n",
        "    threshold=h_dict['V_th'],\n",
        "    device=device,\n",
        "    learn_beta=h_dict['LEARN_BETA'],\n",
        "    learn_threshold=h_dict['LEARN_THRESHOLD']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGHrXdIbZzIM"
      },
      "source": [
        "#**Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGxR-7jfnMiH"
      },
      "source": [
        "---\n",
        "**Objects Creation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O8X73PNoxTBN"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tser_kd.training import EarlyStopping\n",
        "from tser_kd.dataset import RateEncoder, StaticEncoder\n",
        "from tser_kd.model import TSCELoss\n",
        "from tser_kd.utils import AccuracyMonitor\n",
        "\n",
        "\n",
        "# Optimizer\n",
        "if h_dict[\"OPTIMIZER\"] == 'AdamW':\n",
        "    optimizer = optim.AdamW(s_model.parameters(), lr=h_dict['BASE_LR'], weight_decay=h_dict['WEIGHT_DECAY'])\n",
        "elif h_dict[\"OPTIMIZER\"] == 'Adam':\n",
        "    optimizer = optim.Adam(s_model.parameters(), lr=h_dict['BASE_LR'], weight_decay=h_dict['WEIGHT_DECAY'])\n",
        "elif h_dict[\"OPTIMIZER\"] == 'SGD':\n",
        "    optimizer = optim.SGD(s_model.parameters(), lr=h_dict['BASE_LR'], momentum=h_dict[\"MOMENTUM\"], weight_decay=h_dict['WEIGHT_DECAY'])\n",
        "\n",
        "# LR scheduler\n",
        "if h_dict[\"LR_SCHEDULER\"] == 'ReduceLROnPlateau':\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=h_dict[\"LR_PATIENCE\"], factor=h_dict[\"LR_FACTOR\"])\n",
        "elif h_dict[\"LR_SCHEDULER\"] == 'CosineAnnealingLR':\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=h_dict[\"MAX_EPOCHS\"])\n",
        "elif h_dict[\"LR_SCHEDULER\"] == 'StepLR':\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=h_dict[\"LR_STEP\"], gamma=h_dict[\"LR_FACTOR\"])\n",
        "\n",
        "\n",
        "# Losses\n",
        "train_criterion = TSCELoss()\n",
        "eval_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Accuracy monitor\n",
        "acc_monitor = AccuracyMonitor(path=\"best_acc.pth\")\n",
        "\n",
        "# Early stopping\n",
        "es_callback = EarlyStopping(patience=h_dict[\"ES_PATIENCE\"], delta=h_dict[\"ES_DELTA\"], path=\"best_loss.pth\")\n",
        "\n",
        "# Gradient scaler\n",
        "scaler = torch.amp.GradScaler(device='cuda')\n",
        "\n",
        "# Encoder\n",
        "if h_dict[\"ENCODER\"] == \"Rate\":\n",
        "    encoder = RateEncoder(num_steps=h_dict[\"T\"], gain=h_dict[\"GAIN\"])\n",
        "elif h_dict[\"ENCODER\"] == \"Static\":\n",
        "    encoder = StaticEncoder(num_steps=h_dict[\"T\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj5bHrZFnSdj"
      },
      "source": [
        "---\n",
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzDyh1ue-jFQ",
        "outputId": "6e3fa498-baa2-43c9-ee61-8226332d0807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/31 17:10:15 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
            "Epoch 1: 100%|██████████| Batch 1875/1875 , acc=78.86%, loss=0.7126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 40.9s | Train Loss: 0.7126 | Train Acc: 78.86% | Val Loss: 0.1708 | Val Acc1: 95.92% | Val Acc5: 99.89% | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| Batch 1875/1875 , acc=95.88%, loss=0.1550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.3s | Train Loss: 0.1550 | Train Acc: 95.88% | Val Loss: 0.1188 | Val Acc1: 96.70% | Val Acc5: 99.85% | LR: 0.000989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| Batch 1875/1875 , acc=97.28%, loss=0.0978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.4s | Train Loss: 0.0978 | Train Acc: 97.28% | Val Loss: 0.0776 | Val Acc1: 97.85% | Val Acc5: 99.92% | LR: 0.000957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| Batch 1875/1875 , acc=97.85%, loss=0.0740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.0s | Train Loss: 0.0740 | Train Acc: 97.85% | Val Loss: 0.0532 | Val Acc1: 98.46% | Val Acc5: 99.97% | LR: 0.000905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| Batch 1875/1875 , acc=98.26%, loss=0.0585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.9s | Train Loss: 0.0585 | Train Acc: 98.26% | Val Loss: 0.0507 | Val Acc1: 98.45% | Val Acc5: 99.97% | LR: 0.000835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| Batch 1875/1875 , acc=98.64%, loss=0.0469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.0s | Train Loss: 0.0469 | Train Acc: 98.64% | Val Loss: 0.0422 | Val Acc1: 98.68% | Val Acc5: 99.99% | LR: 0.000750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| Batch 1875/1875 , acc=98.91%, loss=0.0372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.2s | Train Loss: 0.0372 | Train Acc: 98.91% | Val Loss: 0.0344 | Val Acc1: 98.94% | Val Acc5: 99.98% | LR: 0.000655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| Batch 1875/1875 , acc=99.12%, loss=0.0311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.9s | Train Loss: 0.0311 | Train Acc: 99.12% | Val Loss: 0.0391 | Val Acc1: 98.69% | Val Acc5: 99.99% | LR: 0.000552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| Batch 1875/1875 , acc=99.35%, loss=0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 40.0s | Train Loss: 0.0236 | Train Acc: 99.35% | Val Loss: 0.0298 | Val Acc1: 99.04% | Val Acc5: 99.99% | LR: 0.000448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| Batch 1875/1875 , acc=99.51%, loss=0.0190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.3s | Train Loss: 0.0190 | Train Acc: 99.51% | Val Loss: 0.0325 | Val Acc1: 98.92% | Val Acc5: 99.99% | LR: 0.000345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| Batch 1875/1875 , acc=99.65%, loss=0.0148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.1s | Train Loss: 0.0148 | Train Acc: 99.65% | Val Loss: 0.0271 | Val Acc1: 99.13% | Val Acc5: 99.99% | LR: 0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| Batch 1875/1875 , acc=99.78%, loss=0.0115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.1s | Train Loss: 0.0115 | Train Acc: 99.78% | Val Loss: 0.0259 | Val Acc1: 99.11% | Val Acc5: 99.99% | LR: 0.000165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| Batch 1875/1875 , acc=99.85%, loss=0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 40.1s | Train Loss: 0.0096 | Train Acc: 99.85% | Val Loss: 0.0273 | Val Acc1: 99.10% | Val Acc5: 100.00% | LR: 0.000095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| Batch 1875/1875 , acc=99.90%, loss=0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.6s | Train Loss: 0.0082 | Train Acc: 99.90% | Val Loss: 0.0263 | Val Acc1: 99.14% | Val Acc5: 99.99% | LR: 0.000043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| Batch 1875/1875 , acc=99.92%, loss=0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 39.6s | Train Loss: 0.0076 | Train Acc: 99.92% | Val Loss: 0.0249 | Val Acc1: 99.17% | Val Acc5: 100.00% | LR: 0.000011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/31 17:21:15 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
            "2025/07/31 17:21:16 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃 View run SCNNS-IS4MNIST at: https://dagshub.com/matteogianferrari/tser-kd.mlflow/#/experiments/1/runs/02fb055178714d089c3a886c1dbecd98\n",
            "🧪 View experiment at: https://dagshub.com/matteogianferrari/tser-kd.mlflow/#/experiments/1\n"
          ]
        }
      ],
      "source": [
        "import pynvml\n",
        "from tser_kd.eval import run_eval\n",
        "from tser_kd.training import run_train\n",
        "\n",
        "\n",
        "# PER FARE UN RESUME SERVE IL MODELLO CHECKPOINT, LA START_EPOCH, LA RUN_ID, E LAST_EPOCH IN SCHEDULER\n",
        "\n",
        "# Sets the MLFlow experiment\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "epoch_i = 0\n",
        "curr_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "# Train the model and log with MLFlow\n",
        "with mlflow.start_run(run_id=None, log_system_metrics=True):\n",
        "    for epoch_i in range(h_dict[\"MAX_EPOCHS\"]):\n",
        "        train_loss, train_acc, epoch_time, train_batch_time = run_train(\n",
        "            epoch_i, train_loader, s_model, train_criterion, optimizer, device, scaler, encoder\n",
        "        )\n",
        "\n",
        "        val_loss, val_acc1, val_acc5, val_batch_time = run_eval(val_loader, s_model, eval_criterion, device, encoder)\n",
        "\n",
        "        # Logging\n",
        "        print(\n",
        "            f\"Time: {epoch_time:.1f}s | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "            f\"Val Loss: {val_loss:.4f} | Val Acc1: {val_acc1:.2f}% | Val Acc5: {val_acc5:.2f}% | LR: {curr_lr:.6f}\"\n",
        "        )\n",
        "\n",
        "        mlflow.log_metrics({\n",
        "            \"learning_rate\": curr_lr, \"train_tsce_loss\": train_loss, \"train_acc\": train_acc, \"val_ce_loss\": val_loss,\n",
        "            \"val_acc1\": val_acc1, \"val_acc5\": val_acc5, \"epoch_time\": epoch_time,\n",
        "            \"train_batch_time\": train_batch_time, \"val_batch_time\": val_batch_time\n",
        "        }, step=epoch_i)\n",
        "\n",
        "        # Updates the LR\n",
        "        if h_dict[\"LR_SCHEDULER\"] == 'ReduceLROnPlateau':\n",
        "            scheduler.step(val_loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        curr_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        # Accuracy monitor\n",
        "        acc_monitor(val_acc1, epoch_i, s_model)\n",
        "\n",
        "        # ES check\n",
        "        if es_callback(val_loss, epoch_i, s_model):\n",
        "            break\n",
        "\n",
        "\n",
        "    # Log hyperparameters\n",
        "    mlflow.log_params(h_dict)\n",
        "\n",
        "    # Log test performance\n",
        "    s_model.load_state_dict(torch.load(\"best_acc.pth\"))\n",
        "    test_ce_loss, test_acc1, test_acc5, _ = run_eval(val_loader, s_model, eval_criterion, device, encoder)\n",
        "    mlflow.log_metrics({\"test_ce_loss\": test_ce_loss, \"test_acc1\": test_acc1, \"test_acc5\": test_acc5})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}