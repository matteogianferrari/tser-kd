{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**ResNet19 Teacher Model - TSER for KD**"
      ],
      "metadata": {
        "id": "ZJSgLCKHiO89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup**"
      ],
      "metadata": {
        "id": "gTnIuCisiTF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Install Libraries**"
      ],
      "metadata": {
        "id": "o3a06Oi9iUrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGDE0GdkiJnR"
      },
      "outputs": [],
      "source": [
        "!pip install snntorch dagshub mlflow pynvml --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**GitHub Code**"
      ],
      "metadata": {
        "id": "GlQFuMlmiZ7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Sets environ variables for GitHub\n",
        "os.environ['GITHUB_TOKEN'] = userdata.get('GITHUB_TOKEN')\n",
        "os.environ['USER'] = userdata.get('USER')\n",
        "\n",
        "# Clones the repo and changes dir\n",
        "!git clone https://${GITHUB_TOKEN}@github.com/${USER}/tser-kd.git\n",
        "%cd tser-kd/"
      ],
      "metadata": {
        "id": "cGhHhLrYiYdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Set Seed for Experiment**"
      ],
      "metadata": {
        "id": "WlBYPnb7ij9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tser_kd.utils import setup_seed\n",
        "\n",
        "setup_seed(42)"
      ],
      "metadata": {
        "id": "8FS9oAXTilUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Device Selection**"
      ],
      "metadata": {
        "id": "3PVPlcWDinBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Selects the device for the experiment\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IFbDJ0ARioMV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**MLFlow Setup**"
      ],
      "metadata": {
        "id": "aNo6C0elivjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from mlflow import MlflowClient\n",
        "import dagshub\n",
        "\n",
        "# Sets environ variables for MLFlow\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = userdata.get('USER')\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = userdata.get('MLFLOW_TRACKING_PASSWORD')\n",
        "\n",
        "# Init DagsHub\n",
        "dagshub.init(repo_owner='matteogianferrari', repo_name='tser-kd', mlflow=True)\n",
        "TRACKING_URI = \"https://dagshub.com/matteogianferrari/tser-kd.mlflow\"\n",
        "\n",
        "# Sets MLFlow tracking URI\n",
        "mlflow.set_tracking_uri(TRACKING_URI)\n",
        "\n",
        "# Sets MLFLow experiment name\n",
        "experiment_name = \"TSER-KD Teacher\""
      ],
      "metadata": {
        "id": "4FM3ENSyiudg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hyperparameters**"
      ],
      "metadata": {
        "id": "cg0MgN6XiziR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparamter dictionary\n",
        "h_dict = {\n",
        "    \"MAX_EPOCHS\": 256, \"BATCH_SIZE\": 2048,                  # Training\n",
        "    \"LR_SCHEDULER\": \"ReduceLROnPlateau\", \"BASE_LR\": 1e-3,   # LR\n",
        "    \"LR_PATIENCE\": 6, \"LR_FACTOR\": 0.666,                   # LR\n",
        "    \"ES_PATIENCE\": 15, \"ES_DELTA\": 5e-4,                    # Early Stopping\n",
        "    \"OPTIMIZER\": \"AdamW\", \"WEIGHT_DECAY\": 5e-4,             # Optimizer\n",
        "    \"HARDWARE\": \"L4\",                                       # GPU\n",
        "    \"AUTO_AUG\": True, \"CUTOUT\": True,                       # Dataset\n",
        "}"
      ],
      "metadata": {
        "id": "24O5yb3ci2Ja"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CIFAR10 Dataset**"
      ],
      "metadata": {
        "id": "-yLgsdVEi_Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Data Loaders Creation**"
      ],
      "metadata": {
        "id": "o1bSU2F3jFl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tser_kd.dataset import load_cifar10_data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, num_classes = load_cifar10_data(auto_aug=h_dict['AUTO_AUG'], cutout=h_dict['CUTOUT'])\n",
        "\n",
        "# Creates the train and test DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=h_dict['BATCH_SIZE'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=h_dict['BATCH_SIZE'], shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "kapsg2rEjHFB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Teacher ResNet-19**\n"
      ],
      "metadata": {
        "id": "PKjHJDfHjaq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**ResNet-19**"
      ],
      "metadata": {
        "id": "21IxGxtYkQGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tser_kd.model.teacher import make_teacher_model\n",
        "\n",
        "\n",
        "# ANN\n",
        "t_model = make_teacher_model(arch='resnet-19', in_channels=3, num_classes=num_classes, device=device)"
      ],
      "metadata": {
        "id": "K05RKAhljeIy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training**"
      ],
      "metadata": {
        "id": "dTPsFdKXF6rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Objects Creation**"
      ],
      "metadata": {
        "id": "-3XELj9Ijjrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tser_kd.training import EarlyStopping\n",
        "\n",
        "\n",
        "# Optimizer\n",
        "if h_dict[\"OPTIMIZER\"] == 'AdamW':\n",
        "    optimizer = optim.AdamW(t_model.parameters(), lr=h_dict['BASE_LR'], weight_decay=h_dict['WEIGHT_DECAY'])\n",
        "elif h_dict[\"OPTIMIZER\"] == 'Adam':\n",
        "    optimizer = optim.Adam(t_model.parameters(), lr=h_dict['BASE_LR'], weight_decay=h_dict['WEIGHT_DECAY'])\n",
        "elif h_dict[\"OPTIMIZER\"] == 'SGD':\n",
        "    optimizer = optim.SGD(t_model.parameters(), lr=h_dict['BASE_LR'], momentum=h_dict[\"MOMENTUM\"], weight_decay=h_dict['WEIGHT_DECAY'])\n",
        "\n",
        "# LR scheduler\n",
        "if h_dict[\"LR_SCHEDULER\"] == 'ReduceLROnPlateau':\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=h_dict[\"LR_PATIENCE\"], factor=h_dict[\"LR_FACTOR\"])\n",
        "elif h_dict[\"LR_SCHEDULER\"] == 'CosineAnnealingLR':\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=h_dict[\"MAX_EPOCHS\"])\n",
        "\n",
        "# Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Early stopping\n",
        "es_callback = EarlyStopping(patience=h_dict[\"ES_PATIENCE\"], delta=h_dict[\"ES_DELTA\"], path=\"best_ckpt.pth\")\n",
        "\n",
        "# Gradient scaler\n",
        "scaler = torch.amp.GradScaler(device='cuda')"
      ],
      "metadata": {
        "id": "SRq_Q_uWjhOI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Training Loop**"
      ],
      "metadata": {
        "id": "N3nTfagMjoqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pynvml\n",
        "from tser_kd.training import run_train\n",
        "from tser_kd.eval import run_eval\n",
        "\n",
        "\n",
        "# Sets the MLFlow experiment\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "epoch_i = 0\n",
        "curr_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "# Train the model and log with MLFlow\n",
        "with mlflow.start_run(log_system_metrics=True):\n",
        "    for epoch_i in range(h_dict[\"MAX_EPOCHS\"]):\n",
        "        train_loss, train_acc, epoch_time, train_batch_time = run_train(\n",
        "            epoch_i, train_loader, t_model, criterion, optimizer, device, scaler\n",
        "        )\n",
        "\n",
        "        val_loss, val_acc1, val_acc5, val_batch_time = run_eval(val_loader, t_model, criterion, device)\n",
        "\n",
        "        # Logging\n",
        "        print(\n",
        "            f\"Time: {epoch_time:.1f}s | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "            f\"Val Loss: {val_loss:.4f} | Val Acc1: {val_acc1:.2f}% | Val Acc5: {val_acc5:.2f}% | LR: {curr_lr:.6f}\"\n",
        "        )\n",
        "\n",
        "        mlflow.log_metrics({\n",
        "            \"learning_rate\": curr_lr, \"train_loss\": train_loss, \"train_acc\": train_acc, \"val_loss\": val_loss,\n",
        "            \"val_acc1\": val_acc1, \"val_acc5\": val_acc5, \"epoch_time\": epoch_time,\n",
        "            \"train_batch_time\": train_batch_time, \"val_batch_time\": val_batch_time\n",
        "        }, step=epoch_i)\n",
        "\n",
        "\n",
        "        # Updates the LR\n",
        "        if h_dict[\"LR_SCHEDULER\"] == 'ReduceLROnPlateau':\n",
        "            scheduler.step(val_loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        curr_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        # ES check\n",
        "        if es_callback(val_loss, epoch_i, t_model):\n",
        "            break\n",
        "\n",
        "\n",
        "    # Log hyperparameters\n",
        "    mlflow.log_params(h_dict)\n",
        "\n",
        "    # Log test performance\n",
        "    t_model.load_state_dict(torch.load(\"best_ckpt.pth\"))\n",
        "    test_loss, test_acc1, test_acc5, _ = run_eval(val_loader, t_model, criterion, device)\n",
        "    mlflow.log_metrics({\"test_loss\": test_loss, \"test_acc1\": test_acc1, \"test_acc5\": test_acc5})"
      ],
      "metadata": {
        "id": "eCPJbkrzjqSl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}