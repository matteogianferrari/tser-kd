import os
import argparse

parser = argparse.ArgumentParser(description="TSER-KD")

parser.add_argument('--run_name', type=str, help='Experiment name.')
parser.add_argument('--group_name', default='kd', type=str, help='Experiment group.')
parser.add_argument('--dataset', default='cifar10', type=str, help='Dataset used to train the model.\nPossible candidates are [cifar10, mnist].')
parser.add_argument('--auto_aug', default=True, type=bool, help='Applies AutoAugmentation on the dataset.\nValid only on cifar10.')
parser.add_argument('--cutout', default=True, type=bool, help='Applies CutOut on the dataset.\nValid only on cifar10.')
parser.add_argument('--batch_size', default=32, type=int, help='Batch size for the dataset.')
parser.add_argument('--num_workers', default=2, type=int, help='Number of threads used by the data loaders.')
parser.add_argument('--t_weight', default=None, type=str, help='State dict path for the teacher model.')
parser.add_argument('--teacher_arch', default='resnet-34', type=str, help='Teacher model architecture.\nPossible models are: [resnet-34, resnet-19, resnet-18].')
parser.add_argument('--snn_grad', default='atan', type=str, help='Student surrogate gradient.')
parser.add_argument('--s_weight', default=None, type=str, help='State dict path for the student model.')
parser.add_argument('--student_arch', default='sresnet-18', type=str, help='Student model architecture.\nPossible models are: [sresnet-19, sresnet-18, scnn-t, scnn-s].')
parser.add_argument('--transfer', default=False, type=bool, help='Flag that handles the transfer learning.')
parser.add_argument('--transfer_weight', default=None, type=str, help='State dict path for transfer learning.')
parser.add_argument('--trainable_weights', default=True, type=bool, help='Flag that handles the trainable weights that are transferred.')
parser.add_argument('--transfer_arch', default=None, type=str, help='Model used to perform transfer learning.\nPossible models are: [resnet-18, resnet-19].')
parser.add_argument('--beta', default=0.5, type=float, help='Membrane decaying parameter for LIF neurons.')
parser.add_argument('--v_th', default=1.0, type=float, help='Membrane threshold for LIF neurons.')
parser.add_argument('--learn_beta', default=False, type=bool, help='Allows learnable membrane decaying parameters for LIF neurons.')
parser.add_argument('--learn_threshold', default=False, type=bool, help='Allows learnable membrane threshold parameters for LIF neurons.')
parser.add_argument('--optimizer', default='adamw', type=str, help='Optimizer for training the model.\nPossible optimizers are: [adamw, sgd].')
parser.add_argument('--lr', default=3e-3, type=float, help='Learning rate.')
parser.add_argument('--wd', default=5e-4, type=float, help='Weight decay for optimizer.')
# parser.add_argument('--momentum', default=0.9, type=float, help='Momentum for optimizer.')
parser.add_argument('--scheduler', default='cosine', type=str, help='Learning rate scheduler for training.\nPossible schedulers are: [cosine, reduce].')
# parser.add_argument('--lr_patience', default=0, type=int, help='LR patience for ReduceLROnPlateau scheduler.')
# parser.add_argument('--lr_factor', default=0.6, type=float, help='LR factor for ReduceLROnPlateau scheduler.')
parser.add_argument('--epochs', default=300, type=int, help='Training epochs.')
parser.add_argument('--alpha', default=1e-2, type=float, help='KL and CE weighting parameter in KD.')
parser.add_argument('--gamma', default=1e-3, type=float, help='ER weighting parameter in KD.')
parser.add_argument('--tau', default=5, type=float, help='Temperature.')
parser.add_argument('--t_steps', default=2, type=int, help='Input sequence lengths in time steps.')
parser.add_argument('--model_path', default='data/teacher_models/best_acc.pth', type=str, help='Path to save the best model weights.')

args = parser.parse_args()
args_dict = vars(args)
